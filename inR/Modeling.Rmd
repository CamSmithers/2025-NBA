---
title: "Exploration 2"
author: "Cam Smithers"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Necessary Packages

```{r}
library(tidyverse)
library(rsample)
library(caret)
library(vip)
set.seed(123)
```

Necessary Data Sets

```{r}
source("/Users/camsmithers/Desktop/Camalytics/NBA/inR/Functions.R")

team_season_stats <- readRDS(
    "/Users/camsmithers/Desktop/Camalytics/NBA/Data-NBA/team_season_stats.rds")

player_regseason_stats <- readRDS(
    "/Users/camsmithers/Desktop/Camalytics/NBA/Data-NBA/plyr_regsn_stats.rds")

usdpo <- readRDS(
    "/Users/camsmithers/Desktop/Camalytics/NBA/Data-NBA/usdpo.rds")
```

Summary

I have been running into issues when creating models to predict the outcomes of games. The issue is my model creates predictions where I know what has already happened, I don't know what will happen in a game that has yet to be played. Therefore, I have two methods by which I can approach this problem.

1.  Determine how the team plays on average, then how they play within one and two standard deviations of the mean.
    1.  Mean: Average or Baseline for Team
    2.  1 SD: Above/Below Average Performance for Team
    3.  2 SD: Significantly Above/Below Average Performance for Team
2.  Use the data from the previous five seasons and the current season to create the models. However, when the models are created the data from the current season have more weight. Having them weigh more will enable a focus on this seasons, while providing historical context. Once the model has been created use the data from the current season to generate fitted values.

------------------------------------------------------------------------

Model 1: Win or Loss

```{r}
usdpo <- usdpo %>%
    mutate(win = factor(win, 
                        levels = c(0, 1),
                        labels = c("Loss", "Win")))
```

```{r}
win_split <- initial_split(usdpo, prop = .7, strata = "win")
win_train <- training(win_split)
win_test <- testing(win_split)
```

```{r}
win_three <- train(
    win ~ tmsn_netpf + pri_op + pri_dp + pri_pp + team + opponent + season + 
        tmsn_netpf_opp + pri_op_opp + pri_dp_opp + pri_pp_opp + tmsn_avgposspts +
        tmsn_avgposspts_opp,
    data = usdpo,
    method = "glm",
    family = "binomial",
    trControl = trainControl(method = "cv", number = 10))

win_four <- train(
    win ~ tmsn_netpf + pri_op + pri_dp + pri_pp + team + opponent + season + 
        tmsn_netpf_opp + pri_op_opp + pri_dp_opp + pri_pp_opp,
    data = usdpo,
    method = "glm",
    family = "binomial",
    trControl = trainControl(method = "cv", number = 10))
win_five <- train(
    win ~ tmsn_netpf + pri_op + pri_dp + pri_pp + team + opponent + season + 
        tmsn_netpf_opp + pri_op_opp + pri_dp_opp + pri_pp_opp + tert_op + tert_dp + 
        tert_op_opp + tert_dp_opp,
    data = usdpo,
    method = "glm",
    family = "binomial",
    trControl = trainControl(method = "cv", number = 10))
```

```{r}
summary(
    resamples(
        list(
            model1 = win_three,
            model2 = win_four,
            model3 = win_five
        )
    )
)$statistics$Accuracy
```

```{r}
pred_class <- predict(win_five, win_train)

confusionMatrix(
    data = relevel(pred_class, ref = "Win"),
    reference = relevel(win_train$win, ref = "Win")
)
```

------------------------------------------------------------------------

Model 2: Magnitude of Outcome
