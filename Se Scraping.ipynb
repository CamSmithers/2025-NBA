{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d00dc6e",
   "metadata": {},
   "source": [
    "## Scraping Using Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d652fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service \n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d8a4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service(executable_path=\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/chromedriver\")\n",
    "driver = webdriver.Chrome(service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838d3550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the URLs for every game from each month\n",
    "\n",
    "nba_months = [\"october\", \"november\", \"december\", \"january\",\n",
    "               \"february\", \"march\", \"april\", \"may\", \"june\"]\n",
    "\n",
    "season_25_links = []\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(service=Service(), options=options)\n",
    "\n",
    "\n",
    "for month in nba_months:\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_2025_games-{month}.html\"\n",
    "    print(f\"Scraping {url}\")\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "\n",
    "    links = driver.find_elements(By.XPATH, '//a[contains(@href, \"/boxscores/\") and contains(text(), \"Box Score\")]')\n",
    "    for link in links:\n",
    "        href = link.get_attribute('href')\n",
    "        if href:\n",
    "            season_25_links.append(href)\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Check results\n",
    "print(season_25_links[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c897f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(season_25_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cee7831",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_games = season_25_links[616:]\n",
    "len(remaining_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb725ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going through the list of links and saving the page as an HTML file\n",
    "\n",
    "game_folder = \"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Games/Games_2024-25\"\n",
    "os.makedirs(game_folder, exist_ok=True)\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "prefs = {\n",
    "    \"profile.managed_default_content_settings.images\": 2,\n",
    "    \"profile.managed_default_content_settings.stylesheets\": 2,\n",
    "    \"profile.managed_default_content_settings.plugins\": 2,\n",
    "    \"profile.managed_default_content_settings.popups\": 2,\n",
    "    \"profile.managed_default_content_settings.geolocation\": 2,\n",
    "    \"profile.managed_default_content_settings.notifications\": 2\n",
    "}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(), options=options)\n",
    "\n",
    "for game in remaining_games:\n",
    "    print(f\"Saving {game}\")\n",
    "    driver.get(game)\n",
    "\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.ID, \"content\"))\n",
    "    )\n",
    "\n",
    "    html = driver.page_source\n",
    "    filename = os.path.join(game_folder, game.split(\"/\")[-1])\n",
    "\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "\n",
    "    time.sleep(random.uniform(1, 4))\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86982c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the season data for individual teams.\n",
    "\n",
    "nba_team_abb_east = [\"CLE\", \"BOS\", \"NYK\", \"IND\", \"MIL\", \"DET\", \"ORL\", \"ATL\", \"CHI\", \"MIA\", \"TOR\", \"BRK\", \"PHI\", \"CHO\", \"WAS\"]\n",
    "nba_team_abb_west = [\"OKC\", \"HOU\", \"LAL\", \"DEN\", \"LAC\", \"GSW\", \"MIN\", \"MEM\", \"SAC\", \"DAL\", \"PHO\", \"POR\", \"SAS\", \"NOP\", \"UTA\"]\n",
    "\n",
    "team_folder = \"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Teams/Teams_2425\"\n",
    "os.makedirs(team_folder, exist_ok=True)\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "prefs = {\n",
    "    \"profile.managed_default_content_settings.images\": 2,\n",
    "    \"profile.managed_default_content_settings.stylesheets\": 2,\n",
    "    \"profile.managed_default_content_settings.plugins\": 2,\n",
    "    \"profile.managed_default_content_settings.popups\": 2,\n",
    "    \"profile.managed_default_content_settings.geolocation\": 2,\n",
    "    \"profile.managed_default_content_settings.notifications\": 2\n",
    "}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(), options=options)\n",
    "\n",
    "for team in nba_team_abb_west:\n",
    "    print(f\"Saving {team}\")\n",
    "    driver.get(f\"https://www.basketball-reference.com/teams/{team}/2025.html\")\n",
    "\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.ID, \"content\"))\n",
    "    )\n",
    "\n",
    "    html = driver.page_source\n",
    "    filename = os.path.join(team_folder, f\"{team}-2025.html\")\n",
    "\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "    \n",
    "    time.sleep(random.uniform(1, 5))\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3b4b31",
   "metadata": {},
   "source": [
    "## Parsing HTML Files for Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5396bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152c0faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_path = Path(\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Games/Games_2024-25\")\n",
    "game_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78010402",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_dfs = []\n",
    "\n",
    "for game in os.listdir(games_path):\n",
    "    with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Games/Games_2024-25/{game}\", encoding=\"utf-8\") as f:\n",
    "        page = f.read()\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "    basic_tables = soup.find_all(id=re.compile(r\"^box-.*-game-basic$\"))\n",
    "\n",
    "    table_dfs = []\n",
    "    for table in basic_tables:\n",
    "        table_id = table.get(\"id\")\n",
    "        table_html = str(table)\n",
    "        df = pd.read_html(StringIO(table_html), header=1)[0]\n",
    "        df[\"team_table_id\"] = table_id\n",
    "        df[\"game_id\"] = game\n",
    "        table_dfs.append(df)\n",
    "\n",
    "    # Add the opposing team table id\n",
    "    if len(table_dfs) == 2:\n",
    "        table_dfs[0][\"opp_team_table_id\"] = table_dfs[1][\"team_table_id\"]\n",
    "        table_dfs[1][\"opp_team_table_id\"] = table_dfs[0][\"team_table_id\"]\n",
    "\n",
    "    basic_dfs.extend(table_dfs)\n",
    "\n",
    "basic_tables_combined = pd.concat(basic_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1fbd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_tables_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5170d289",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_dfs = []\n",
    "\n",
    "for game in os.listdir(games_path):\n",
    "    with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Games/Games_2024-25/{game}\", encoding=\"utf-8\") as f:\n",
    "        page = f.read()\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "    advanced_tables = soup.find_all(id=re.compile(r\"^box-.*-game-advanced$\"))\n",
    "\n",
    "    table_dfs = []\n",
    "    for table in advanced_tables:\n",
    "        table_id = table.get(\"id\")\n",
    "        table_html = str(table)\n",
    "        df = pd.read_html(StringIO(table_html), header=1)[0]\n",
    "        df[\"team_table_id\"] = table_id\n",
    "        df[\"game_id\"] = game\n",
    "        table_dfs.append(df)\n",
    "\n",
    "    # Add the opposing team table id\n",
    "    if len(table_dfs) == 2:\n",
    "        table_dfs[0][\"opp_team_table_id\"] = table_dfs[1][\"team_table_id\"]\n",
    "        table_dfs[1][\"opp_team_table_id\"] = table_dfs[0][\"team_table_id\"]\n",
    "\n",
    "    advanced_dfs.extend(table_dfs)\n",
    "\n",
    "advanced_tables_combined = pd.concat(advanced_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c62da66",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_tables_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318bf90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_tables_combined.to_csv(\"/Users/camsmithers/Desktop/Camalytics/NBA/Data-NBA/BasicBox2425.csv\")\n",
    "advanced_tables_combined.to_csv(\"/Users/camsmithers/Desktop/Camalytics/NBA/Data-NBA/AdvancedBox2425.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033947fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_teams = Path(\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Teams/Teams_2425/All_Teams\")\n",
    "playoff_teams = Path(\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Teams/Teams_2425/Playoff_Teams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22b35b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_general_dfs = []\n",
    "\n",
    "for team in os.listdir(all_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Teams/Teams_2425/All_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if \"team_and_opponent\" in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"team_and_opponent\")\n",
    "        df = pd.read_html(StringIO(str(table)))[0]\n",
    "        df[\"team_id\"] = team\n",
    "        all_general_dfs.append(df)\n",
    "\n",
    "all_general_dfs = pd.concat(all_general_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd7324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_misc_dfs = []\n",
    "\n",
    "for team in os.listdir(all_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Teams/Teams_2425/All_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if \"team_misc\" in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"team_misc\")\n",
    "        df = pd.read_html(StringIO(str(table)), header=1)[0]\n",
    "        df[\"team_id\"] = team\n",
    "        all_misc_dfs.append(df)\n",
    "\n",
    "all_misc_combined = pd.concat(all_misc_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27e09d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pgs_dfs = []\n",
    "\n",
    "for team in os.listdir(all_teams):\n",
    "    with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Teams/Teams_2425/All_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "        page = f.read()\n",
    "    \n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "    tables = soup.find_all(id=\"per_game_stats\")\n",
    "\n",
    "    for table in tables:\n",
    "        table_html = str(table)\n",
    "        df = pd.read_html(StringIO(table_html))[0]\n",
    "        df[\"team_id\"] = team\n",
    "        all_pgs_dfs.append(df)\n",
    "all_pgs_combined = pd.concat(all_pgs_dfs, ignore_index=True)\n",
    "\n",
    "all_pgs_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db2c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_pgs_dfs = []\n",
    "\n",
    "for team in os.listdir(playoff_teams):\n",
    "    with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Teams/Teams_2425/Playoff_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "        page = f.read()\n",
    "    \n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "    tables = soup.find_all(id=\"per_game_stats_post\")\n",
    "\n",
    "    for table in tables:\n",
    "        table_html = str(table)\n",
    "        df = pd.read_html(StringIO(table_html))[0]\n",
    "        df[\"team_id\"] = team\n",
    "        playoff_pgs_dfs.append(df)\n",
    "playoff_pgs_combined = pd.concat(playoff_pgs_dfs, ignore_index=True)\n",
    "\n",
    "playoff_pgs_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8d8010",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_totals_dfs = []\n",
    "\n",
    "for team in os.listdir(all_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Teams/Teams_2425/All_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if \"totals_stats\" in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"totals_stats\")\n",
    "        df = pd.read_html(StringIO(str(table)))[0]\n",
    "        df[\"team_id\"] = team\n",
    "        all_totals_dfs.append(df)\n",
    "\n",
    "all_totals_combined = pd.concat(all_totals_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22775907",
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_totals_dfs = []\n",
    "\n",
    "for team in os.listdir(playoff_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Teams/Teams_2425/Playoff_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if \"totals_stats_post\" in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"totals_stats_post\")\n",
    "        df = pd.read_html(StringIO(str(table)))[0]\n",
    "        df[\"team_id\"] = team\n",
    "        playoff_totals_dfs.append(df)\n",
    "\n",
    "playoff_totals_combined = pd.concat(playoff_totals_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075e9eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_per36_dfs = []\n",
    "\n",
    "for team in os.listdir(all_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Teams/Teams_2425/All_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        tables = soup.find_all(id=\"per_minute_stats\")\n",
    "\n",
    "        for table in tables:\n",
    "            table_html = str(table)\n",
    "            df = pd.read_html(StringIO(table_html))[0]\n",
    "            df[\"team_id\"] = team\n",
    "            all_per36_dfs.append(df)\n",
    "\n",
    "all_per36_combined = pd.concat(all_per36_dfs, ignore_index=True)\n",
    "\n",
    "all_per36_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d5e87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_per36_dfs = []\n",
    "\n",
    "for team in os.listdir(playoff_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Teams/Teams_2425/Playoff_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        tables = soup.find_all(id=\"per_minute_stats_post\")\n",
    "\n",
    "        for table in tables:\n",
    "            table_html = str(table)\n",
    "            df = pd.read_html(StringIO(table_html))[0]\n",
    "            df[\"team_id\"] = team\n",
    "            playoff_per36_dfs.append(df)\n",
    "\n",
    "playoff_per36_combined = pd.concat(playoff_per36_dfs, ignore_index=True)\n",
    "\n",
    "playoff_per36_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8a5a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_per100_dfs = []\n",
    "\n",
    "for team in os.listdir(all_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Teams/Teams_2425/All_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if \"per_poss\" in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"per_poss\")\n",
    "        df = pd.read_html(StringIO(str(table)))[0]\n",
    "        df[\"team_id\"] = team\n",
    "        all_per100_dfs.append(df)\n",
    "\n",
    "all_per100_combined = pd.concat(all_per100_dfs, ignore_index=True)\n",
    "\n",
    "all_per100_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66b3196",
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_per100_dfs = []\n",
    "\n",
    "for team in os.listdir(playoff_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Teams/Teams_2425/Playoff_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if \"per_poss_post\" in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"per_poss_post\")\n",
    "        df = pd.read_html(StringIO(str(table)))[0]\n",
    "        df[\"team_id\"] = team\n",
    "        playoff_per100_dfs.append(df)\n",
    "\n",
    "playoff_per100_combined = pd.concat(playoff_per100_dfs, ignore_index=True)\n",
    "\n",
    "playoff_per100_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af527ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_advanced_dfs = []\n",
    "\n",
    "for team in os.listdir(all_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Teams/Teams_2425/All_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if 'id=\"advanced\"' in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"advanced\")\n",
    "        df = pd.read_html(StringIO(str(table)))[0]\n",
    "        df[\"team_id\"] = team\n",
    "        all_advanced_dfs.append(df)\n",
    "\n",
    "all_advanced_combined = pd.concat(all_advanced_dfs, ignore_index=True)\n",
    "\n",
    "all_advanced_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a2e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_advanced_dfs = []\n",
    "\n",
    "for team in os.listdir(playoff_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Teams/Teams_2425/Playoff_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if \"advanced_post\" in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"advanced_post\")\n",
    "        df = pd.read_html(StringIO(str(table)))[0]\n",
    "        df[\"team_id\"] = team\n",
    "        playoff_advanced_dfs.append(df)\n",
    "\n",
    "playoff_advanced_combined = pd.concat(playoff_advanced_dfs, ignore_index=True)\n",
    "\n",
    "playoff_advanced_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf950f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_adjshooting_dfs = []\n",
    "\n",
    "for team in os.listdir(all_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Teams/Teams_2425/All_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if \"adj_shooting\" in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"adj_shooting\")\n",
    "        df = pd.read_html(StringIO(str(table)), header=1)[0]\n",
    "        df[\"team_id\"] = team\n",
    "        all_adjshooting_dfs.append(df)\n",
    "\n",
    "all_adjshooting_combined = pd.concat(all_adjshooting_dfs, ignore_index=True)\n",
    "\n",
    "all_adjshooting_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedf65fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_adjshooting_dfs = []\n",
    "\n",
    "for team in os.listdir(playoff_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Teams/Teams_2425/Playoff_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if \"adj_shooting_post\" in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"adj_shooting_post\")\n",
    "        df = pd.read_html(StringIO(str(table)), header=1)[0]\n",
    "        df[\"team_id\"] = team\n",
    "        playoff_adjshooting_dfs.append(df)\n",
    "\n",
    "playoff_adjshooting_combined = pd.concat(playoff_adjshooting_dfs, ignore_index=True)\n",
    "\n",
    "playoff_adjshooting_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefc7f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shooting_dfs = []\n",
    "\n",
    "for team in os.listdir(all_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Teams/Teams_2425/All_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if 'id=\"shooting\"' in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"shooting\")\n",
    "        df = pd.read_html(StringIO(str(table)), header=1)[0]\n",
    "        df[\"team_id\"] = team\n",
    "        all_shooting_dfs.append(df)\n",
    "\n",
    "all_shooting_combined = pd.concat(all_shooting_dfs, ignore_index=True)\n",
    "\n",
    "all_shooting_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e123071",
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_shooting_dfs = []\n",
    "\n",
    "for team in os.listdir(playoff_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Teams/Teams_2425/Playoff_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if 'id=\"shooting_post\"' in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"shooting_post\")\n",
    "        df = pd.read_html(StringIO(str(table)), header=1)[0]\n",
    "        df[\"team_id\"] = team\n",
    "        playoff_shooting_dfs.append(df)\n",
    "\n",
    "playoff_shooting_combined = pd.concat(playoff_shooting_dfs, ignore_index=True)\n",
    "\n",
    "playoff_shooting_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5dc817",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pbp_dfs = []\n",
    "\n",
    "for team in os.listdir(all_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Teams/Teams_2425/All_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if \"pbp_stats\" in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"pbp_stats\")\n",
    "        df = pd.read_html(StringIO(str(table)), header=1)[0]\n",
    "        df[\"team_id\"] = team\n",
    "        all_pbp_dfs.append(df)\n",
    "\n",
    "all_pbp_combined = pd.concat(all_pbp_dfs, ignore_index=True)\n",
    "\n",
    "all_pbp_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226eab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_pbp_dfs = []\n",
    "\n",
    "for team in os.listdir(playoff_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Teams/Teams_2425/Playoff_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if \"pbp_stats_post\" in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"pbp_stats_post\")\n",
    "        df = pd.read_html(StringIO(str(table)), header=1)[0]\n",
    "        df[\"team_id\"] = team\n",
    "        playoff_pbp_dfs.append(df)\n",
    "\n",
    "playoff_pbp_combined = pd.concat(playoff_pbp_dfs, ignore_index=True)\n",
    "\n",
    "playoff_pbp_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17791349",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_team_dfs_dict = {\n",
    "    \"pgs\": all_pgs_combined,\n",
    "    \"misc\": all_misc_combined,\n",
    "    \"totals\": all_totals_combined,\n",
    "    \"per36\": all_per36_combined,\n",
    "    \"per100\": all_per100_combined,\n",
    "    \"advanced\": all_advanced_combined,\n",
    "    \"adjshooting\": all_adjshooting_combined,\n",
    "    \"shooting\": all_shooting_combined,\n",
    "    \"pbp\": all_pbp_combined\n",
    "}\n",
    "\n",
    "for name, df in all_team_dfs_dict.items():\n",
    "    df.to_csv(f\"/Users/camsmithers/Desktop/Camalytics/NBA/Data-NBA/{name}-2425.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c083f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_team_dfs_dict = {\n",
    "    \"playoff_pgs\": playoff_pgs_combined,\n",
    "    \"playoff_totals\": playoff_totals_combined,\n",
    "    \"playoff_per36\": playoff_per36_combined,\n",
    "    \"playoff_per100\": playoff_per100_combined,\n",
    "    \"playoff_advanced\": playoff_advanced_combined,\n",
    "    \"playoff_adjshooting\": playoff_adjshooting_combined,\n",
    "    \"playoff_shooting\": playoff_shooting_combined,\n",
    "    \"playoff_pbp\": playoff_pbp_combined\n",
    "}\n",
    "\n",
    "for name, df in playoff_team_dfs_dict.items():\n",
    "    df.to_csv(f\"/Users/camsmithers/Desktop/Camalytics/NBA/Data-NBA/{name}-2425.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
