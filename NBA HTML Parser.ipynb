{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d740624e",
   "metadata": {},
   "source": [
    "# Parsing HTML Files for Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e45bd8",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b6ee289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f336549a",
   "metadata": {},
   "source": [
    "## Box Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e81ae58",
   "metadata": {},
   "source": [
    "### Game File Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4482e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_path = Path(\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/AllGames\")\n",
    "game_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6481394d",
   "metadata": {},
   "source": [
    "### Scraping Basic Box Score Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a382a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_dfs = []\n",
    "\n",
    "for game in os.listdir(games_path):\n",
    "    with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/AllGames/{game}\", encoding=\"utf-8\") as f:\n",
    "        page = f.read()\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "    basic_tables = soup.find_all(id=re.compile(r\"^box-.*-game-basic$\"))\n",
    "\n",
    "    table_dfs = []\n",
    "    for table in basic_tables:\n",
    "        table_id = table.get(\"id\")\n",
    "        table_html = str(table)\n",
    "        df = pd.read_html(StringIO(table_html), header=1)[0]\n",
    "        df[\"team_table_id\"] = table_id\n",
    "        df[\"game_id\"] = game\n",
    "        table_dfs.append(df)\n",
    "\n",
    "    # Add the opposing team table id\n",
    "    if len(table_dfs) == 2:\n",
    "        table_dfs[0][\"opp_team_table_id\"] = table_dfs[1][\"team_table_id\"]\n",
    "        table_dfs[1][\"opp_team_table_id\"] = table_dfs[0][\"team_table_id\"]\n",
    "\n",
    "    basic_dfs.extend(table_dfs)\n",
    "\n",
    "basic_tables_combined = pd.concat(basic_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfa6ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_tables_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9569f63",
   "metadata": {},
   "source": [
    "#### Exporting Basic Box Score to CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004a23cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_tables_combined.to_csv(\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/BasicBox.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131235d4",
   "metadata": {},
   "source": [
    "### Scraping Advanced Box Score Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26b6ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_dfs = []\n",
    "\n",
    "for game in os.listdir(games_path):\n",
    "    with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/AllGames/{game}\", encoding=\"utf-8\") as f:\n",
    "        page = f.read()\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "    advanced_tables = soup.find_all(id=re.compile(r\"^box-.*-game-advanced$\"))\n",
    "\n",
    "    table_dfs = []\n",
    "    for table in advanced_tables:\n",
    "        table_id = table.get(\"id\")\n",
    "        table_html = str(table)\n",
    "        df = pd.read_html(StringIO(table_html), header=1)[0]\n",
    "        df[\"team_table_id\"] = table_id\n",
    "        df[\"game_id\"] = game\n",
    "        table_dfs.append(df)\n",
    "\n",
    "    # Add the opposing team table id\n",
    "    if len(table_dfs) == 2:\n",
    "        table_dfs[0][\"opp_team_table_id\"] = table_dfs[1][\"team_table_id\"]\n",
    "        table_dfs[1][\"opp_team_table_id\"] = table_dfs[0][\"team_table_id\"]\n",
    "\n",
    "    advanced_dfs.extend(table_dfs)\n",
    "\n",
    "advanced_tables_combined = pd.concat(advanced_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f45661",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_tables_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7130f9b1",
   "metadata": {},
   "source": [
    "#### Exporting Advanced Box Scores to CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fafce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_tables_combined.to_csv(\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/AdvancedBox.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b87e4e8",
   "metadata": {},
   "source": [
    "## Team Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dec2af3",
   "metadata": {},
   "source": [
    "### IDs to Collect\n",
    "* Team Misc: team_misc\n",
    "* Team Per Game: per_game_stats, per_game_stats\n",
    "* Team Totals: totals_stats, totals_stats_post\n",
    "* Per 36 Min: per_minute_stats, per_minute_stats_post\n",
    "* Per 100 Poss: per_poss, per_poss_post\n",
    "* Advanced: advanced, advanced_post\n",
    "* Adjusted Shooting: adj_shooting, adj_shooting_post\n",
    "* Shooting: shooting, shooting_post\n",
    "* Play by Play: pbp_stats, pbp_stats_post\n",
    "\n",
    "### Scrape Type\n",
    "* Regular\n",
    "    * Per Game\n",
    "    * Per 36 Min\n",
    "* In Comments\n",
    "    * Team Totals\n",
    "    * Per 100 Poss\n",
    "    * Advanced\n",
    "    * Adjusted Shooting\n",
    "    * Shooting\n",
    "    * Play by Play\n",
    "    * Team Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98d4274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_teams = Path(\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/Teams/All_Teams\")\n",
    "playoff_teams = Path(\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/Teams/Playoff_Teams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9abeda",
   "metadata": {},
   "source": [
    "#### Team and Opponent Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59fd92f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_general_dfs = []\n",
    "\n",
    "for team in os.listdir(all_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/Teams/All_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if \"team_and_opponent\" in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"team_and_opponent\")\n",
    "        df = pd.read_html(StringIO(str(table)))[0]\n",
    "        df[\"team_id\"] = team\n",
    "        all_general_dfs.append(df)\n",
    "\n",
    "all_general_dfs = pd.concat(all_general_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c960e00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_general_dfs.to_csv(\"/Users/camsmithers/Desktop/Camalytics/NBA/Data-NBA/all_general.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda59521",
   "metadata": {},
   "source": [
    "#### Team Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82a85ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_misc_dfs = []\n",
    "\n",
    "for team in os.listdir(all_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/Teams/All_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if \"team_misc\" in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"team_misc\")\n",
    "        df = pd.read_html(StringIO(str(table)), header=1)[0]\n",
    "        df[\"team_id\"] = team\n",
    "        all_misc_dfs.append(df)\n",
    "\n",
    "all_misc_combined = pd.concat(all_misc_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a3c497",
   "metadata": {},
   "source": [
    "#### Per Game Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347828d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pgs_dfs = []\n",
    "\n",
    "for team in os.listdir(all_teams):\n",
    "    with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/Teams/All_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "        page = f.read()\n",
    "    \n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "    tables = soup.find_all(id=\"per_game_stats\")\n",
    "\n",
    "    for table in tables:\n",
    "        table_html = str(table)\n",
    "        df = pd.read_html(StringIO(table_html))[0]\n",
    "        df[\"team_id\"] = team\n",
    "        all_pgs_dfs.append(df)\n",
    "all_pgs_combined = pd.concat(all_pgs_dfs, ignore_index=True)\n",
    "\n",
    "all_pgs_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9675745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_pgs_dfs = []\n",
    "\n",
    "for team in os.listdir(playoff_teams):\n",
    "    with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/Teams/Playoff_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "        page = f.read()\n",
    "    \n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "    tables = soup.find_all(id=\"per_game_stats_post\")\n",
    "\n",
    "    for table in tables:\n",
    "        table_html = str(table)\n",
    "        df = pd.read_html(StringIO(table_html))[0]\n",
    "        df[\"team_id\"] = team\n",
    "        playoff_pgs_dfs.append(df)\n",
    "playoff_pgs_combined = pd.concat(playoff_pgs_dfs, ignore_index=True)\n",
    "\n",
    "playoff_pgs_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d395818",
   "metadata": {},
   "source": [
    "#### Team Totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45298cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_totals_dfs = []\n",
    "\n",
    "for team in os.listdir(all_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/Teams/All_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if \"totals_stats\" in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"totals_stats\")\n",
    "        df = pd.read_html(StringIO(str(table)))[0]\n",
    "        df[\"team_id\"] = team\n",
    "        all_totals_dfs.append(df)\n",
    "\n",
    "all_totals_combined = pd.concat(all_totals_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a900dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_totals_dfs = []\n",
    "\n",
    "for team in os.listdir(playoff_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/Teams/Playoff_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if \"totals_stats_post\" in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"totals_stats_post\")\n",
    "        df = pd.read_html(StringIO(str(table)))[0]\n",
    "        df[\"team_id\"] = team\n",
    "        playoff_totals_dfs.append(df)\n",
    "\n",
    "playoff_totals_combined = pd.concat(playoff_totals_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c756188",
   "metadata": {},
   "source": [
    "#### Per 36 Min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d742cfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_per36_dfs = []\n",
    "\n",
    "for team in os.listdir(all_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/Teams/All_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        tables = soup.find_all(id=\"per_minute_stats\")\n",
    "\n",
    "        for table in tables:\n",
    "            table_html = str(table)\n",
    "            df = pd.read_html(StringIO(table_html))[0]\n",
    "            df[\"team_id\"] = team\n",
    "            all_per36_dfs.append(df)\n",
    "\n",
    "all_per36_combined = pd.concat(all_per36_dfs, ignore_index=True)\n",
    "\n",
    "all_per36_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bdfcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_per36_dfs = []\n",
    "\n",
    "for team in os.listdir(playoff_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/Teams/Playoff_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        tables = soup.find_all(id=\"per_minute_stats_post\")\n",
    "\n",
    "        for table in tables:\n",
    "            table_html = str(table)\n",
    "            df = pd.read_html(StringIO(table_html))[0]\n",
    "            df[\"team_id\"] = team\n",
    "            playoff_per36_dfs.append(df)\n",
    "\n",
    "playoff_per36_combined = pd.concat(playoff_per36_dfs, ignore_index=True)\n",
    "\n",
    "playoff_per36_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcbaaa6",
   "metadata": {},
   "source": [
    "#### Per 100 Poss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f5538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_per100_dfs = []\n",
    "\n",
    "for team in os.listdir(all_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/Teams/All_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if \"per_poss\" in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"per_poss\")\n",
    "        df = pd.read_html(StringIO(str(table)))[0]\n",
    "        df[\"team_id\"] = team\n",
    "        all_per100_dfs.append(df)\n",
    "\n",
    "all_per100_combined = pd.concat(all_per100_dfs, ignore_index=True)\n",
    "\n",
    "all_per100_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e6bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_per100_dfs = []\n",
    "\n",
    "for team in os.listdir(playoff_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/Teams/Playoff_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if \"per_poss_post\" in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"per_poss_post\")\n",
    "        df = pd.read_html(StringIO(str(table)))[0]\n",
    "        df[\"team_id\"] = team\n",
    "        playoff_per100_dfs.append(df)\n",
    "\n",
    "playoff_per100_combined = pd.concat(playoff_per100_dfs, ignore_index=True)\n",
    "\n",
    "playoff_per100_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc20885",
   "metadata": {},
   "source": [
    "#### Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b880ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_advanced_dfs = []\n",
    "\n",
    "for team in os.listdir(all_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/Teams/All_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if 'id=\"advanced\"' in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"advanced\")\n",
    "        df = pd.read_html(StringIO(str(table)))[0]\n",
    "        df[\"team_id\"] = team\n",
    "        all_advanced_dfs.append(df)\n",
    "\n",
    "all_advanced_combined = pd.concat(all_advanced_dfs, ignore_index=True)\n",
    "\n",
    "all_advanced_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994ae248",
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_advanced_dfs = []\n",
    "\n",
    "for team in os.listdir(playoff_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/Teams/Playoff_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if \"advanced_post\" in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"advanced_post\")\n",
    "        df = pd.read_html(StringIO(str(table)))[0]\n",
    "        df[\"team_id\"] = team\n",
    "        playoff_advanced_dfs.append(df)\n",
    "\n",
    "playoff_advanced_combined = pd.concat(playoff_advanced_dfs, ignore_index=True)\n",
    "\n",
    "playoff_advanced_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e90fbe3",
   "metadata": {},
   "source": [
    "#### Adjusted Shooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ac696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_adjshooting_dfs = []\n",
    "\n",
    "for team in os.listdir(all_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/Teams/All_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if \"adj_shooting\" in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"adj_shooting\")\n",
    "        df = pd.read_html(StringIO(str(table)), header=1)[0]\n",
    "        df[\"team_id\"] = team\n",
    "        all_adjshooting_dfs.append(df)\n",
    "\n",
    "all_adjshooting_combined = pd.concat(all_adjshooting_dfs, ignore_index=True)\n",
    "\n",
    "all_adjshooting_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea4cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_adjshooting_dfs = []\n",
    "\n",
    "for team in os.listdir(playoff_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/Teams/Playoff_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if \"adj_shooting_post\" in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"adj_shooting_post\")\n",
    "        df = pd.read_html(StringIO(str(table)), header=1)[0]\n",
    "        df[\"team_id\"] = team\n",
    "        playoff_adjshooting_dfs.append(df)\n",
    "\n",
    "playoff_adjshooting_combined = pd.concat(playoff_adjshooting_dfs, ignore_index=True)\n",
    "\n",
    "playoff_adjshooting_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f4c20e",
   "metadata": {},
   "source": [
    "#### Shooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cffae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shooting_dfs = []\n",
    "\n",
    "for team in os.listdir(all_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/Teams/All_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if 'id=\"shooting\"' in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"shooting\")\n",
    "        df = pd.read_html(StringIO(str(table)), header=1)[0]\n",
    "        df[\"team_id\"] = team\n",
    "        all_shooting_dfs.append(df)\n",
    "\n",
    "all_shooting_combined = pd.concat(all_shooting_dfs, ignore_index=True)\n",
    "\n",
    "all_shooting_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409377b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_shooting_dfs = []\n",
    "\n",
    "for team in os.listdir(playoff_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/Teams/Playoff_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if 'id=\"shooting_post\"' in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"shooting_post\")\n",
    "        df = pd.read_html(StringIO(str(table)), header=1)[0]\n",
    "        df[\"team_id\"] = team\n",
    "        playoff_shooting_dfs.append(df)\n",
    "\n",
    "playoff_shooting_combined = pd.concat(playoff_shooting_dfs, ignore_index=True)\n",
    "\n",
    "playoff_shooting_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ce56ee",
   "metadata": {},
   "source": [
    "#### Play by Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a452fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pbp_dfs = []\n",
    "\n",
    "for team in os.listdir(all_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/Teams/All_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if \"pbp_stats\" in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"pbp_stats\")\n",
    "        df = pd.read_html(StringIO(str(table)), header=1)[0]\n",
    "        df[\"team_id\"] = team\n",
    "        all_pbp_dfs.append(df)\n",
    "\n",
    "all_pbp_combined = pd.concat(all_pbp_dfs, ignore_index=True)\n",
    "\n",
    "all_pbp_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96718b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_pbp_dfs = []\n",
    "\n",
    "for team in os.listdir(playoff_teams):\n",
    "    if team.endswith(\".html\"):\n",
    "        with open(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/Teams/Playoff_Teams/{team}\", encoding=\"ISO-8859-1\") as f:\n",
    "            page = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comment = next(c for c in soup.find_all(string=lambda text: isinstance(text, Comment)) if \"pbp_stats_post\" in c)\n",
    "        table = BeautifulSoup(comment, \"html.parser\").find(id=\"pbp_stats_post\")\n",
    "        df = pd.read_html(StringIO(str(table)), header=1)[0]\n",
    "        df[\"team_id\"] = team\n",
    "        playoff_pbp_dfs.append(df)\n",
    "\n",
    "playoff_pbp_combined = pd.concat(playoff_pbp_dfs, ignore_index=True)\n",
    "\n",
    "playoff_pbp_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad45368",
   "metadata": {},
   "source": [
    "### All Teams Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703f04c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_team_dfs_dict = {\n",
    "    \"pgs\": all_pgs_combined,\n",
    "    \"misc\": all_misc_combined,\n",
    "    \"totals\": all_totals_combined,\n",
    "    \"per36\": all_per36_combined,\n",
    "    \"per100\": all_per100_combined,\n",
    "    \"advanced\": all_advanced_combined,\n",
    "    \"adjshooting\": all_adjshooting_combined,\n",
    "    \"shooting\": all_shooting_combined,\n",
    "    \"pbp\": all_pbp_combined\n",
    "}\n",
    "\n",
    "for name, df in all_team_dfs_dict.items():\n",
    "    df.to_csv(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/{name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc648e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_team_dfs_dict = {\n",
    "    \"playoff_pgs\": playoff_pgs_combined,\n",
    "    \"playoff_totals\": playoff_totals_combined,\n",
    "    \"playoff_per36\": playoff_per36_combined,\n",
    "    \"playoff_per100\": playoff_per100_combined,\n",
    "    \"playoff_advanced\": playoff_advanced_combined,\n",
    "    \"playoff_adjshooting\": playoff_adjshooting_combined,\n",
    "    \"playoff_shooting\": playoff_shooting_combined,\n",
    "    \"playoff_pbp\": playoff_pbp_combined\n",
    "}\n",
    "\n",
    "for name, df in playoff_team_dfs_dict.items():\n",
    "    df.to_csv(f\"/Users/camsmithers/Desktop/Camalytics/CamalyticsEnv/Projects/Sports/NBA/Data/{name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ba022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CamalyticsEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
